{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42ZvEGJ00E_i"
   },
   "source": [
    "# COMP9517: Computer Vision 2024 T3 Project Method: UNet\n",
    "\n",
    "## Our Unet and UDTransNet are using the same pipeline.\n",
    "## Just Choose the UNet in the `Config.py` file.\n",
    "```python\n",
    "# Choose the model\n",
    "# model_name = 'UDTransNet'\n",
    "model_name = 'UNet'\n",
    "```\n",
    "\n",
    "## After the model change, the training and testing process is the same as UDTransNet.\n",
    "## So, feel free to jump to Step 6.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Clone the UDTransNet model from github\n",
    "\n",
    "### We recommend running this project on Google Colab.\n",
    "\n",
    "### The pretrained three model weights using UNet can be accessed by using this [Google Drive link](https://drive.google.com/drive/folders/1qb72K2x3251G2_OJTlKDhs7qQBlkRzQD?usp=drive_link)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Da6RHO4rJ_d7",
    "outputId": "fcbdfa50-2186-46f8-f1dc-3ef159f46de0"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/McGregorWwww/UDTransNet.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Install the required packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QAuzdNb-KDc0",
    "outputId": "ddf3b802-d8e9-4c18-db13-5eac87a2a6bf"
   },
   "outputs": [],
   "source": [
    "%cd UDTransNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZHss03Nh2HXS"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "PjdqkfajMhYI",
    "outputId": "7c40ecea-bea7-4f92-874b-28b92099da81"
   },
   "outputs": [],
   "source": [
    "!pip install tensorboardX\n",
    "!pip install ml_collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Download the SeaTurtleID2022 dataset from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3xriZAVRN7uq",
    "outputId": "3617e917-c8b4-41bc-831c-5500e0e37b53"
   },
   "outputs": [],
   "source": [
    "!curl -L -o ./archive.zip https://www.kaggle.com/api/v1/datasets/download/wildlifedatasets/seaturtleid2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "JjrkEkfdXleA",
    "outputId": "79e02c7d-d204-4431-d34c-65806e8f8d25"
   },
   "outputs": [],
   "source": [
    "!unzip archive.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Generate masks of the dataset with areas in ['turtle', 'head', 'flippers']\n",
    "\n",
    "### In this method, I need to partition the turtle into three distinct areas to perform binary segmentation over each area.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o8KNuPyIX0ln",
    "outputId": "bdfa62d5-8822-401d-b1f8-3c05dad3374e"
   },
   "outputs": [],
   "source": [
    "%mv turtles-data/ ./datasets/\n",
    "%cd ./datasets/turtles-data/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CC_t8AqlXfMt",
    "outputId": "3a3637c2-268b-40e8-9aaf-09d74275f007"
   },
   "outputs": [],
   "source": [
    "# Generate masked images with areas\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Choose one area to generate\n",
    "# area = 'turtle'\n",
    "area = 'head'\n",
    "# area = 'flipper'\n",
    "\n",
    "image_dir = ''\n",
    "annotation_file = './annotations.json'\n",
    "metadata_file = './metadata_splits.csv'\n",
    "train_valid_folder_mask = f'./{area}_train_valid_folder_mask'\n",
    "test_folder_mask = f'./{area}_test_folder_mask'\n",
    "\n",
    "# Read the COCO styled annotation file\n",
    "coco = COCO(annotation_file)\n",
    "\n",
    "metadata = pd.read_csv(metadata_file)\n",
    "\n",
    "# Get one category's ids e.g. \"turtle\"\n",
    "category_ids = coco.getCatIds(catNms=[area])\n",
    "image_ids = coco.getImgIds(catIds=category_ids)\n",
    "\n",
    "Path(train_valid_folder_mask).mkdir(parents=True, exist_ok=True)\n",
    "Path(test_folder_mask).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# \n",
    "def generate_and_save_mask(image_id):\n",
    "    img_info = coco.loadImgs(image_id)[0]\n",
    "    image_path = os.path.join(image_dir, img_info['file_name'])\n",
    "\n",
    "    image = Image.open(image_path)\n",
    "    image = np.array(image)\n",
    "\n",
    "    ann_ids = coco.getAnnIds(imgIds=img_info['id'], catIds=category_ids)\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "    mask = np.zeros((img_info['height'], img_info['width']), dtype=np.uint8)\n",
    "\n",
    "    for ann in anns:\n",
    "        mask = np.maximum(mask, coco.annToMask(ann))\n",
    "\n",
    "    split_label = metadata.loc[metadata['file_name'] == img_info['file_name'], 'split_closed'].values[0]\n",
    "\n",
    "    mask_image = Image.fromarray(mask * 255)\n",
    "    if split_label in ['train', 'valid']:\n",
    "        mask_image.save(os.path.join(train_valid_folder_mask, f\"{img_info['file_name'].split('/')[-1].split('.')[0]}_mask.png\"))\n",
    "    elif split_label == 'test':\n",
    "        mask_image.save(os.path.join(test_folder_mask, f\"{img_info['file_name'].split('/')[-1].split('.')[0]}_mask.png\"))\n",
    "\n",
    "for image_id in tqdm(image_ids, desc=\"Generating masks\"):\n",
    "    generate_and_save_mask(image_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Divide all images into a training folder and a testing folder based on the 'split_closed' column in the CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "6pUVHaXVXu2p",
    "outputId": "0309fcc6-0abe-4fc7-8688-f7c91ef4ae56"
   },
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# area = 'turtle'\n",
    "area = 'head'\n",
    "# area = 'flipper'\n",
    "\n",
    "image_dir = '/content/UDTransNet/datasets/turtles-data/data'\n",
    "annotation_file = '/content/UDTransNet/datasets/turtles-data/data/annotations.json'\n",
    "metadata_file = '/content/UDTransNet/datasets/turtles-data/data/metadata_splits.csv'\n",
    "train_valid_folder = f'/content/UDTransNet/datasets/turtles-data/data/{area}_train_valid_folder'\n",
    "test_folder = f'/content/UDTransNet/datasets/turtles-data/data/{area}_test_folder'\n",
    "\n",
    "coco = COCO(annotation_file)\n",
    "\n",
    "metadata = pd.read_csv(metadata_file)\n",
    "\n",
    "# Get one category's ids e.g. \"turtle\"\n",
    "category_ids = coco.getCatIds(catNms=[area])\n",
    "image_ids = coco.getImgIds(catIds=category_ids)\n",
    "\n",
    "Path(train_valid_folder).mkdir(parents=True, exist_ok=True)\n",
    "Path(test_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Go through all the ids of the image and split them into training folder or testing folder base on the split label\n",
    "for image_id in tqdm(image_ids, desc=\"Processing images\"):\n",
    "    img_info = coco.loadImgs(image_id)[0]\n",
    "    image_path = os.path.join(image_dir, img_info['file_name'])\n",
    "\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image {image_path} not found. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Get all the annotation ids\n",
    "    ann_ids = coco.getAnnIds(imgIds=img_info['id'])\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "    \n",
    "    # Check if the area was in the annotations\n",
    "    if len(anns) > 0:\n",
    "        # Get split label from the matadata_split.csv\n",
    "        split_label = metadata.loc[metadata['file_name'] == img_info['file_name'], 'split_closed'].values\n",
    "\n",
    "        if len(split_label) == 0:\n",
    "            print(f\"No metadata found for image {img_info['file_name']}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        split_label = split_label[0]\n",
    "        if split_label in ['train', 'valid']:\n",
    "            target_folder = train_valid_folder\n",
    "        elif split_label == 'test':\n",
    "            target_folder = test_folder\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        target_path = os.path.join(target_folder, os.path.basename(image_path))\n",
    "        try:\n",
    "            Path(target_path).write_bytes(Path(image_path).read_bytes())\n",
    "            print(f\"Copied {image_path} to {target_folder}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error copying {image_path}: {e}\")\n",
    "    else:\n",
    "        print(f\"Image {img_info['file_name']} does not contain '{area}' annotation. Skipping...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Create training and testing folders for the models\n",
    "\n",
    "- The “img” folder in both training and testing folders is intended to store original images.\n",
    "- The “labelcol” folder in both training and testing folders is intended to store masked ground truth images.\n",
    "\n",
    "Then prepare the datasets in the following format for easy use of the code:\n",
    "```text\n",
    "├── datasets\n",
    "│   ├── Turtle\n",
    "│   │   ├── Test_Folder\n",
    "│   │   │   ├── img\n",
    "│   │   │   └── labelcol\n",
    "│   │   └── Train_Folder\n",
    "│   │       ├── img\n",
    "│   │       └── labelcol\n",
    "│   ├── Turtle_H\n",
    "│   │   ├── Test_Folder\n",
    "│   │   │   ├── img\n",
    "│   │   │   └── labelcol\n",
    "│   │   └── Train_Folder\n",
    "│   │       ├── img\n",
    "│   │       └── labelcol\n",
    "│   └── Turtle_F\n",
    "│       ├── Test_Folder\n",
    "│       │   ├── img\n",
    "│       │   └── labelcol\n",
    "│       └── Train_Folder\n",
    "│           ├── img\n",
    "│           └── labelcol\n",
    "```\n",
    "\n",
    "\n",
    "### Move the split images into the corresponding folders as specified above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ticpxofXAcR",
    "outputId": "65f90f11-64c0-4604-881b-39bc33470c2f"
   },
   "outputs": [],
   "source": [
    "%cd datasets\n",
    "%mkdir Turtle\n",
    "%cd Turtle\n",
    "%mkdir Test_Folder Train_Folder\n",
    "%mkdir Test_Folder/img Test_Folder/labelcol\n",
    "%mkdir Train_Folder/img Train_Folder/labelcol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W18VEyeXORQe",
    "outputId": "4d90e422-e5cb-4a95-b301-a622c0f188e3"
   },
   "outputs": [],
   "source": [
    "%cd /content/UDTransNet/datasets\n",
    "%mkdir Turtle_H\n",
    "%cd Turtle_H\n",
    "%mkdir Test_Folder Train_Folder\n",
    "%mkdir Test_Folder/img Test_Folder/labelcol\n",
    "%mkdir Train_Folder/img Train_Folder/labelcol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JWe2s9x7Tv-y",
    "outputId": "c87acc96-903a-45cf-e0c2-12739eee42a2"
   },
   "outputs": [],
   "source": [
    "%cd /content/UDTransNet/datasets\n",
    "%mkdir Turtle_F\n",
    "%cd Turtle_F\n",
    "%mkdir Test_Folder Train_Folder\n",
    "%mkdir Test_Folder/img Test_Folder/labelcol\n",
    "%mkdir Train_Folder/img Train_Folder/labelcol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zeCGYNNZXuOn"
   },
   "source": [
    "### Step 7: Start the training\n",
    "\n",
    "## IF YOU WANT TO TRAIN IT YOURSELF, PLEASE REPLACE THE `Config.py`, `Load_Dataset.py`, `test_kfold.py` AND `train_kfold.py` FILES IN THE CLONED PROJECT WITH OURS.\n",
    "\n",
    "## ⚠️Please remember to rename the original image folder that was split into two parts to “img,” and rename the ground truth image (mask) to “labelcol.”⚠️\n",
    "\n",
    "## ⚠️You must organize them in the structure showed in Step 6!⚠️\n",
    "\n",
    "### The first step is to change the settings in `Config.py`, all the configurations including learning rate, batch size and etc. are in it.\n",
    "\n",
    "We optimize the convolution parameters in U-Net and the DAT parameters together with a single loss. Run:\n",
    "\n",
    "```bash\n",
    "python train_kfold.py\n",
    "```\n",
    "\n",
    "The results including log files, model weights, etc., are in '[TaskName]_kfold' folder, e.g., 'Turtle_kfold'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rGJ40NHCQIan",
    "outputId": "45a7b5d8-72db-41bf-c306-014aa74f8983"
   },
   "outputs": [],
   "source": [
    "!python train_kfold.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Start Testing\n",
    "\n",
    "### !! First, change the session name in `Config.py` as the training phase. !!\n",
    "\n",
    "### IF YOU ARE USING OUR PRE-TRAINED WEIGHT. \n",
    "### PUT THE MODEL TRAINED FOR `FLIPPERS` IN `Turtle_F_kfold/UDTransNet/Test_session_10.27_04h15/models/fold_1`\n",
    "### PLEASE USE 'Test_session_10.27_04h15' for Flippers\n",
    "### PUT THE MODEL TRAINED FOR `HEAD` IN `Turtle_H_kfold/UDTransNet/Test_session_10.27_03h17/models/fold_1`\n",
    "### PLEASE USE 'Test_session_10.27_03h17' for Head\n",
    "### PUT THE MODEL TRAINED FOR `CARAPACE` IN `Turtle_kfold/UDTransNet/Test_session_10.27_02h23/models/fold_1`\n",
    "### PLEASE USE 'Test_session_10.27_02h23' for Carapace\n",
    "\n",
    "Then, for Turtle, Turtle_H and Turtle_F, run:\n",
    "\n",
    "```bash\n",
    "python test_kfold.py\n",
    "```\n",
    "\n",
    "### You can get the Dice and IoU scores and the visualization results `in the visualized folder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MFkpxx64W2TQ",
    "outputId": "8f2aba60-5171-44d1-a539-6d982638f8e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting medpy\n",
      "  Downloading medpy-0.5.2.tar.gz (156 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.3/156.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from medpy) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from medpy) (1.26.4)\n",
      "Collecting SimpleITK>=2.1 (from medpy)\n",
      "  Downloading SimpleITK-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
      "Downloading SimpleITK-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: medpy\n",
      "  Building wheel for medpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for medpy: filename=MedPy-0.5.2-cp310-cp310-linux_x86_64.whl size=762840 sha256=ff4ade2fa5087b9b1bacb08cdfee651a1de71a21e18cc9af145a8457b51014a7\n",
      "  Stored in directory: /root/.cache/pip/wheels/a1/b8/63/bdf557940ec60d1b8822e73ff9fbe7727ac19f009d46b5d175\n",
      "Successfully built medpy\n",
      "Installing collected packages: SimpleITK, medpy\n",
      "Successfully installed SimpleITK-2.4.0 medpy-0.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install medpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iweAiW4mdM6n",
    "outputId": "bdeede39-f44d-4c8e-a483-291380bf41d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Turtle\n",
      "Model loaded !\n",
      "==== 1 models loaded ====\n",
      "Test visualize: 100%|████████████████| 10/10 [00:02<00:00,  3.49img/s]\n",
      "inference_time 0.2883608818054199\n",
      "dice_5folds: [97.19]\n",
      "iou_5folds: [94.68]\n",
      "dice: 97.19+nan\n",
      "iou: 94.68+nan\n"
     ]
    }
   ],
   "source": [
    "!python test_kfold.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation Results visualized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can get the Dice and IoU scores and the visualization results `in the visualized folder`\n",
    "\n",
    "### Here is the table containing all the results from three parts\n",
    "| Metrics   | Head  | Carapace | Flippers | \n",
    "|-|-|-|-|\n",
    "|**DICE**|`87.49%`|`96.81%`|`88.58%`|\n",
    "|**mIoU**|`80.87%`|`94.51%`|`81.63%`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_folder = \"./Turtle_visualize_test\"\n",
    "image_folder_F = \"./Turtle_F_visualize_test\"\n",
    "image_folder_H = \"./Turtle_H_visualize_test\"\n",
    "\n",
    "image_files = sorted([f for f in os.listdir(image_folder) if f.endswith(('.png', '.jpg', '.jpeg', '.bmp'))])\n",
    "image_files_F = sorted([f for f in os.listdir(image_folder_F) if f.endswith(('.png', '.jpg', '.jpeg', '.bmp'))])\n",
    "image_files_H = sorted([f for f in os.listdir(image_folder_H) if f.endswith(('.png', '.jpg', '.jpeg', '.bmp'))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print all segmented Carapace\n",
    "if not image_files:\n",
    "    print(\"No images in this folder!\")\n",
    "else:\n",
    "    plt.figure(figsize=(10, len(image_files) * 3))\n",
    "\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        plt.subplot(len(image_files) // 2 + len(image_files) % 2, 2, i + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(image_file)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all segmented Flippers\n",
    "if not image_files_F:\n",
    "    print(\"No images in this folder!\")\n",
    "else:\n",
    "    plt.figure(figsize=(10, len(image_files_F) * 3))\n",
    "\n",
    "    for i, image_file in enumerate(image_files_F):\n",
    "        image_path = os.path.join(image_folder_F, image_file)\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        plt.subplot(len(image_files_F) // 2 + len(image_files_F) % 2, 2, i + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(image_file)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all segmented Head\n",
    "if not image_files_H:\n",
    "    print(\"No images in this folder!\")\n",
    "else:\n",
    "    plt.figure(figsize=(10, len(image_files_H) * 3))\n",
    "\n",
    "    for i, image_file in enumerate(image_files_H):\n",
    "        image_path = os.path.join(image_folder_H, image_file)\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        plt.subplot(len(image_files_H) // 2 + len(image_files_H) % 2, 2, i + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(image_file)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
